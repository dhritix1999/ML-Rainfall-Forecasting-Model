{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0565403b5684cc72ad1df74761f0871441393b3f5c164e2ef07e55caf67f37f7a",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "565403b5684cc72ad1df74761f0871441393b3f5c164e2ef07e55caf67f37f7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "We took our encoded data from other notebook and instantiated it in this notebook. The X consists of features and the Y consists of labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[18.5 19.7 22.4 ... 18.9 18.6  1. ]\n [23.7 36.3  2.2 ... 26.5 34.1  1. ]\n [18.4 27.5  0.  ... 19.7 24.4  0. ]\n ...\n [10.  20.1  0.  ... 14.3 19.   0. ]\n [ 9.9 25.3  0.  ... 14.4 24.5  0. ]\n [14.4 19.8 13.2 ... 15.4 16.6  1. ]]\n"
     ]
    }
   ],
   "source": [
    "%store -r X\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "%store -r Y\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "source": [
    "KNN Algorithm:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "precision [0.6509434  0.95522388 0.74336283 0.78761062 0.82882883]\nrecall [0.66346154 0.61538462 0.81553398 0.86407767 0.89320388]\nf1_score [0.65714286 0.74853801 0.77777778 0.82407407 0.85981308]\nTest_accuracy:  [0.65217391 0.79227053 0.76811594 0.81553398 0.85436893]\nTrain_accuracy:  [0.93583535 0.92493947 0.92615012 0.92261185 0.91293833]\nConfusion-Matrix\n[[404 112]\n [119 398]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'f1': 'f1'}\n",
    "\n",
    "cv_result = cross_validate(neigh, X, Y, cv=5, scoring=scoring, return_train_score= True)\n",
    "\n",
    "print('precision', cv_result['test_precision'])\n",
    "print('recall', cv_result['test_recall'])\n",
    "print('f1_score', cv_result['test_f1'])\n",
    "print('Test_accuracy: ', cv_result['test_accuracy'])\n",
    "print('Train_accuracy: ', cv_result['train_accuracy'])\n",
    "\n",
    "\n",
    "y_pred = cross_val_predict(neigh, X, Y, cv=5)\n",
    "conf_mat = confusion_matrix(Y, y_pred)\n",
    "print('Confusion-Matrix')\n",
    "print(conf_mat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "Naive Bayes Algorithm:"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "precision [0.71       0.83333333 0.66393443 0.84158416 0.75      ]\nrecall [0.68269231 0.67307692 0.78640777 0.82524272 0.87378641]\nf1_score [0.69607843 0.74468085 0.72       0.83333333 0.80717489]\nTest_accuracy:  [0.70048309 0.76811594 0.69565217 0.83495146 0.79126214]\nTrain_accuracy:  [0.81355932 0.78208232 0.78692494 0.77871826 0.77871826]\nConfusion-Matrix\n[[386 130]\n [120 397]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB(var_smoothing=1e-09)\n",
    "\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'f1': 'f1'}\n",
    "\n",
    "cv_result = cross_validate(clf, X, Y, cv=5, scoring=scoring, return_train_score= True)\n",
    "\n",
    "print('precision', cv_result['test_precision'])\n",
    "print('recall', cv_result['test_recall'])\n",
    "print('f1_score', cv_result['test_f1'])\n",
    "print('Test_accuracy: ', cv_result['test_accuracy'])\n",
    "print('Train_accuracy: ', cv_result['train_accuracy'])\n",
    "\n",
    "\n",
    "y_pred = cross_val_predict(clf, X, Y, cv=5)\n",
    "conf_mat = confusion_matrix(Y, y_pred)\n",
    "print('Confusion-Matrix')\n",
    "print(conf_mat)"
   ]
  },
  {
   "source": [
    "We ran our data with the KNN algorithm and the Naive Bayes algorithm. Within the KNN algorthim, our TP and TN was greater in the confusion matrix. For the KNN algorthim, the best n_neighbours was 3. For the Naive Bayes Algorthim, the var_smoothings best values was 1e-09, the default itself was the best. The precision, recall and f1_score for both algorithms were similar."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}